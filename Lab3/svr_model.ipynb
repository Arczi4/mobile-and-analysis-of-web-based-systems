{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = [\n",
    "#         {'svr__kernel': ['linear'], 'svr__C': [10]},\n",
    "#         # {'svr__kernel': ['rbf'], 'svr__C': [1.0, 3.0],},\n",
    "#     ]\n",
    "\n",
    "# svr_pipeline = Pipeline([(\"svr\", SVR())])\n",
    "# grid_search = GridSearchCV(svr_pipeline, param_grid, cv=3,\n",
    "#                            scoring='neg_root_mean_squared_error')\n",
    "# grid_search.fit(train_set[cols[1:]], train_set[cols[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = pd.read_csv(os.path.join('data', 'merged_upload.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['operator']\n",
    "numerical_cols = data.columns[:-1].to_list()\n",
    "numerical_cols.remove('speed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = data.drop('speed', axis=1)\n",
    "y = data['speed']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_cols),\n",
    "        ('num', StandardScaler(), numerical_cols)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with the preprocessing steps and the SVR model\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', SVR())\n",
    "])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Evaluate the model using the mean squared error metric\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e373d2d52e93e3fe6dfc10e107db42f312930fd786c07579306f364fb7ff5aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
